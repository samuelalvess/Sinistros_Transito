{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2309ae05",
   "metadata": {},
   "source": [
    "# ETL — RAW → SILVER (Sinistros 2025) usando DDL (PostgreSQL)\n",
    "\n",
    "Este notebook:\n",
    "1. Lê o CSV **RAW** (`datatran2025.csv`)\n",
    "2. Aplica as transformações definidas para a **SILVER**\n",
    "3. Executa o **DDL** para criar `silver.silver_sinistros` no PostgreSQL\n",
    "4. Carrega os dados na tabela (modo padrão: **reload**)\n",
    "\n",
    "> Rodar no **VS Code** (kernel local). PostgreSQL no Docker."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d33138e",
   "metadata": {},
   "source": [
    "# Dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81fc8345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\daniel\\onedrive\\documentos\\sinistros2\\.venv\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\daniel\\onedrive\\documentos\\sinistros2\\.venv\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: sqlalchemy in c:\\users\\daniel\\onedrive\\documentos\\sinistros2\\.venv\\lib\\site-packages (2.0.46)\n",
      "Requirement already satisfied: psycopg2-binary in c:\\users\\daniel\\onedrive\\documentos\\sinistros2\\.venv\\lib\\site-packages (2.9.11)\n",
      "Requirement already satisfied: sqlparse in c:\\users\\daniel\\onedrive\\documentos\\sinistros2\\.venv\\lib\\site-packages (0.5.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\daniel\\onedrive\\documentos\\sinistros2\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata in c:\\users\\daniel\\onedrive\\documentos\\sinistros2\\.venv\\lib\\site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\daniel\\onedrive\\documentos\\sinistros2\\.venv\\lib\\site-packages (from sqlalchemy) (3.3.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\daniel\\onedrive\\documentos\\sinistros2\\.venv\\lib\\site-packages (from sqlalchemy) (4.15.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\daniel\\onedrive\\documentos\\sinistros2\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install pandas numpy sqlalchemy psycopg2-binary sqlparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600c834f",
   "metadata": {},
   "source": [
    "# Configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e40a4ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectado! host=127.0.0.1 port=5433 db=sinistros_2025 user=postgres\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sqlparse\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# CONFIG (ajuste conforme seu ambiente)\n",
    "os.environ[\"POSTGRES_HOST\"] = os.getenv(\"POSTGRES_HOST\", \"127.0.0.1\")\n",
    "os.environ[\"POSTGRES_PORT\"] = os.getenv(\"POSTGRES_PORT\", \"5433\")\n",
    "os.environ[\"POSTGRES_DB\"] = os.getenv(\"POSTGRES_DB\", \"sinistros_2025\")\n",
    "os.environ[\"POSTGRES_USER\"] = os.getenv(\"POSTGRES_USER\", \"postgres\")\n",
    "os.environ[\"POSTGRES_PASSWORD\"] = os.getenv(\"POSTGRES_PASSWORD\", \"dan1920\")\n",
    "\n",
    "user = os.environ[\"POSTGRES_USER\"]\n",
    "pwd  = os.environ[\"POSTGRES_PASSWORD\"]\n",
    "host = os.environ[\"POSTGRES_HOST\"]\n",
    "port = os.environ[\"POSTGRES_PORT\"]\n",
    "db   = os.environ[\"POSTGRES_DB\"]\n",
    "\n",
    "engine = create_engine(f\"postgresql+psycopg2://{user}:{pwd}@{host}:{port}/{db}\", pool_pre_ping=True)\n",
    "\n",
    "# teste de conexão\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"SELECT 1\"))\n",
    "print(f\"Conectado! host={host} port={port} db={db} user={user}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a13726",
   "metadata": {},
   "source": [
    "# Extração RAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed870088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV encontrado em: c:\\Users\\Daniel\\OneDrive\\Documentos\\Sinistros2\\Sinistros_Transito\\Data Layer\\raw\\datatran2025.csv\n",
      "Shape inicial: (65683, 30)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>data_inversa</th>\n",
       "      <th>dia_semana</th>\n",
       "      <th>horario</th>\n",
       "      <th>uf</th>\n",
       "      <th>br</th>\n",
       "      <th>km</th>\n",
       "      <th>municipio</th>\n",
       "      <th>causa_acidente</th>\n",
       "      <th>tipo_acidente</th>\n",
       "      <th>...</th>\n",
       "      <th>feridos_graves</th>\n",
       "      <th>ilesos</th>\n",
       "      <th>ignorados</th>\n",
       "      <th>feridos</th>\n",
       "      <th>veiculos</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>regional</th>\n",
       "      <th>delegacia</th>\n",
       "      <th>uop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>652493</td>\n",
       "      <td>01/01/2025</td>\n",
       "      <td>quarta-feira</td>\n",
       "      <td>06:20:00</td>\n",
       "      <td>SP</td>\n",
       "      <td>116</td>\n",
       "      <td>225</td>\n",
       "      <td>GUARULHOS</td>\n",
       "      <td>Reação tardia ou ineficiente do condutor</td>\n",
       "      <td>Tombamento</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-23,48586772</td>\n",
       "      <td>-46,54075317</td>\n",
       "      <td>SPRF-SP</td>\n",
       "      <td>DEL01-SP</td>\n",
       "      <td>UOP01-DEL01-SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>652519</td>\n",
       "      <td>01/01/2025</td>\n",
       "      <td>quarta-feira</td>\n",
       "      <td>07:50:00</td>\n",
       "      <td>CE</td>\n",
       "      <td>116</td>\n",
       "      <td>546,2</td>\n",
       "      <td>PENAFORTE</td>\n",
       "      <td>Pista esburacada</td>\n",
       "      <td>Colisão frontal</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>-7,812288</td>\n",
       "      <td>-39,08333306</td>\n",
       "      <td>SPRF-CE</td>\n",
       "      <td>DEL05-CE</td>\n",
       "      <td>UOP03-DEL05-CE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>652522</td>\n",
       "      <td>01/01/2025</td>\n",
       "      <td>quarta-feira</td>\n",
       "      <td>08:45:00</td>\n",
       "      <td>PR</td>\n",
       "      <td>369</td>\n",
       "      <td>88,2</td>\n",
       "      <td>CORNELIO PROCOPIO</td>\n",
       "      <td>Reação tardia ou ineficiente do condutor</td>\n",
       "      <td>Colisão traseira</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-23,182565</td>\n",
       "      <td>-50,637228</td>\n",
       "      <td>SPRF-PR</td>\n",
       "      <td>DEL07-PR</td>\n",
       "      <td>UOP05-DEL07-PR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id data_inversa    dia_semana   horario  uf   br     km  \\\n",
       "0  652493   01/01/2025  quarta-feira  06:20:00  SP  116    225   \n",
       "1  652519   01/01/2025  quarta-feira  07:50:00  CE  116  546,2   \n",
       "2  652522   01/01/2025  quarta-feira  08:45:00  PR  369   88,2   \n",
       "\n",
       "           municipio                            causa_acidente  \\\n",
       "0          GUARULHOS  Reação tardia ou ineficiente do condutor   \n",
       "1          PENAFORTE                          Pista esburacada   \n",
       "2  CORNELIO PROCOPIO  Reação tardia ou ineficiente do condutor   \n",
       "\n",
       "      tipo_acidente  ... feridos_graves ilesos ignorados feridos veiculos  \\\n",
       "0        Tombamento  ...              0      0         1       1        2   \n",
       "1   Colisão frontal  ...              0      1         4       1        6   \n",
       "2  Colisão traseira  ...              0      2         0       3        2   \n",
       "\n",
       "       latitude     longitude  regional  delegacia             uop  \n",
       "0  -23,48586772  -46,54075317   SPRF-SP   DEL01-SP  UOP01-DEL01-SP  \n",
       "1     -7,812288  -39,08333306   SPRF-CE   DEL05-CE  UOP03-DEL05-CE  \n",
       "2    -23,182565    -50,637228   SPRF-PR   DEL07-PR  UOP05-DEL07-PR  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_raw_csv() -> Path:\n",
    "    p = Path.cwd()\n",
    "    for _ in range(10):\n",
    "        candidate = p / \"Data Layer\" / \"raw\" / \"datatran2025.csv\"\n",
    "        if candidate.exists():\n",
    "            return candidate\n",
    "        if p == p.parent:\n",
    "            break\n",
    "        p = p.parent\n",
    "    candidate = Path(\"datatran2025.csv\")\n",
    "    if candidate.exists():\n",
    "        return candidate\n",
    "    raise FileNotFoundError(\"Não encontrei o CSV RAW. Coloque em 'Data Layer/raw/' ou ajuste o path\")\n",
    "\n",
    "RAW_PATH = find_raw_csv()\n",
    "print(\"CSV encontrado em:\", RAW_PATH)\n",
    "\n",
    "# Ler CSV\n",
    "df = pd.read_csv(RAW_PATH, encoding=\"latin-1\", sep=\";\", low_memory=False)\n",
    "print(f\"Shape inicial: {df.shape}\")\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582ade0e",
   "metadata": {},
   "source": [
    "# Transformação "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e8128a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte SIM/NÃO para boolean\n",
    "def sim_nao_to_bool(s: pd.Series) -> pd.Series:\n",
    "    s = s.astype(\"string\").str.strip().str.upper()\n",
    "    return s.map({\n",
    "        \"SIM\": True, \"S\": True, \"TRUE\": True,\n",
    "        \"NÃO\": False, \"NAO\": False, \"N\": False, \"FALSE\": False\n",
    "    }).astype(\"boolean\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8723bbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remover duplicatas\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# preencher strings nulas\n",
    "text_cols = df.select_dtypes(include=[\"string\"]).columns.tolist()\n",
    "for c in text_cols:\n",
    "    df[c] = df[c].fillna(\"\").astype(str).str.strip().str.upper()\n",
    "\n",
    "# numéricos: preencher nulos com 0 e tratar negativos\n",
    "num_cols = [\"pessoas\",\"mortos\",\"ilesos\",\"feridos\",\"feridos_leves\",\"feridos_graves\",\"ignorados\",\"veiculos\"]\n",
    "for c in num_cols:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "        df.loc[df[c]<0, c] = np.nan\n",
    "        df[c] = df[c].round(0).astype(\"Int64\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c301fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removidas 0 linhas com NULLs em colunas obrigatórias\n"
     ]
    }
   ],
   "source": [
    "required_cols = [\n",
    "    \"id\", \"data_acidente\", \"hora_acidente\", \"uf\",\n",
    "    \"municipio\", \"br\", \"pessoas\", \"mortos\", \"feridos\", \"ilesos\", \"veiculos\"\n",
    "]\n",
    "required_cols = [c for c in required_cols if c in df.columns]\n",
    "\n",
    "before = len(df)\n",
    "df = df.dropna(subset=required_cols).copy()\n",
    "after = len(df)\n",
    "print(f\"Removidas {before - after:,} linhas com NULLs em colunas obrigatórias\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d889a311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colunas a remover\n",
    "DROP_COLS = [\"km\",\"feridos_leves\",\"feridos_graves\",\"ignorados\",\"regional\",\"delegacia\",\"uop\"]\n",
    "df = df.drop(columns=[c for c in DROP_COLS if c in df.columns], errors=\"ignore\")\n",
    "\n",
    "# renomear\n",
    "RENAME = {\"data_inversa\":\"data_acidente\", \"horario\":\"hora_acidente\", \"uso_solo\":\"area_urbana\"}\n",
    "df = df.rename(columns={k:v for k,v in RENAME.items() if k in df.columns})\n",
    "\n",
    "# area_urbana: SIM/NÃO -> boolean\n",
    "if \"area_urbana\" in df.columns:\n",
    "    df[\"area_urbana\"] = sim_nao_to_bool(df[\"area_urbana\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a7ca0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datas\n",
    "if \"data_acidente\" in df.columns:\n",
    "    df[\"data_acidente\"] = pd.to_datetime(df[\"data_acidente\"], dayfirst=True, errors=\"coerce\").dt.date\n",
    "\n",
    "# horas\n",
    "if \"hora_acidente\" in df.columns:\n",
    "    h = df[\"hora_acidente\"].astype(\"string\")\n",
    "    t1 = pd.to_datetime(h, format=\"%H:%M\", errors=\"coerce\")\n",
    "    t2 = pd.to_datetime(h, format=\"%H:%M:%S\", errors=\"coerce\")\n",
    "    df[\"hora_acidente\"] = t1.fillna(t2).dt.time\n",
    "\n",
    "# latitude/longitude\n",
    "if \"latitude\" in df.columns:\n",
    "    df[\"latitude\"] = pd.to_numeric(df[\"latitude\"].astype(\"string\").str.replace(\",\", \".\", regex=False), errors=\"coerce\")\n",
    "    df.loc[~df[\"latitude\"].between(-90,90),\"latitude\"] = np.nan\n",
    "\n",
    "if \"longitude\" in df.columns:\n",
    "    df[\"longitude\"] = pd.to_numeric(df[\"longitude\"].astype(\"string\").str.replace(\",\", \".\", regex=False), errors=\"coerce\")\n",
    "    df.loc[~df[\"longitude\"].between(-180,180),\"longitude\"] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7efa87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in required_cols:\n",
    "    if df[c].dtype.name in [\"Int64\",\"float64\"]:\n",
    "        df[c] = df[c].fillna(0).astype(\"Int64\")\n",
    "    elif df[c].dtype.name in [\"object\",\"string\"]:\n",
    "        df[c] = df[c].fillna(\"UNKNOWN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b051796b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de valores nulos restantes nas colunas obrigatórias: 0\n"
     ]
    }
   ],
   "source": [
    "# Lista de colunas obrigatórias para o DW / merges\n",
    "required_cols_dw = [\n",
    "    \"id\", \"data_acidente\", \"hora_acidente\", \"uf\", \"municipio\", \"br\",\n",
    "    \"tipo_acidente\", \"causa_acidente\", \"classificacao_acidente\",\n",
    "    \"fase_dia\", \"condicao_metereologica\", \"tipo_pista\", \"tracado_via\", \"sentido_via\",\n",
    "    \"pessoas\",\"mortos\",\"feridos\",\"ilesos\",\"veiculos\",\"area_urbana\",\n",
    "    \"latitude\",\"longitude\"\n",
    "]\n",
    "\n",
    "# 3️⃣ Preencher numéricos nulos com 0\n",
    "num_cols = [\"pessoas\",\"mortos\",\"feridos\",\"ilesos\",\"veiculos\",\"latitude\",\"longitude\"]\n",
    "for c in num_cols:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\").fillna(0)\n",
    "        if c not in [\"latitude\",\"longitude\"]:\n",
    "            df[c] = df[c].astype(\"Int64\")\n",
    "\n",
    "# 4️⃣ Garantir booleano area_urbana\n",
    "if \"area_urbana\" in df.columns:\n",
    "    df[\"area_urbana\"] = df[\"area_urbana\"].astype(\"boolean\").fillna(False)\n",
    "\n",
    "# 5️⃣ Conferir nulos restantes\n",
    "nulls_remaining = df[required_cols_dw].isna().sum().sum()\n",
    "print(f\"Total de valores nulos restantes nas colunas obrigatórias: {nulls_remaining}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53476063",
   "metadata": {},
   "source": [
    "# Carregamento dos dados na Silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e609eedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DDL Silver executado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "DDL_PATH = r\"C:\\Users\\Daniel\\OneDrive\\Documentos\\Sinistros2\\Sinistros_Transito\\Data Layer\\silver\\ddl.sql\"  # ajuste seu caminho\n",
    "ddl_sql = open(DDL_PATH,'r',encoding=\"utf-8\").read()\n",
    "\n",
    "ddl_clean = sqlparse.format(ddl_sql, strip_comments=True)\n",
    "commands = [cmd.strip() for cmd in sqlparse.split(ddl_clean) if cmd.strip()]\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    for cmd in commands:\n",
    "        conn.execute(text(cmd))\n",
    "\n",
    "print(\"DDL Silver executado com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f9ad300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silver carregada: 65,683 registros\n"
     ]
    }
   ],
   "source": [
    "TARGET_SCHEMA = \"silver\"\n",
    "TARGET_TABLE  = \"silver_sinistros\"\n",
    "\n",
    "# criar schema se não existir\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(text(f\"CREATE SCHEMA IF NOT EXISTS {TARGET_SCHEMA}\"))\n",
    "\n",
    "# ajustar colunas do DF para o banco\n",
    "cols_in_db = pd.read_sql(\n",
    "    f\"\"\"\n",
    "    SELECT column_name\n",
    "    FROM information_schema.columns\n",
    "    WHERE table_schema='{TARGET_SCHEMA}' AND table_name='{TARGET_TABLE}'\n",
    "    ORDER BY ordinal_position\n",
    "    \"\"\",\n",
    "    engine\n",
    ")[\"column_name\"].tolist()\n",
    "\n",
    "df_load = df[[c for c in df.columns if c in cols_in_db]].copy()\n",
    "\n",
    "# remover linhas sem id\n",
    "if \"id\" in df_load.columns:\n",
    "    df_load = df_load[df_load[\"id\"].notna()].copy()\n",
    "\n",
    "# to_sql\n",
    "df_load.to_sql(\n",
    "    name=TARGET_TABLE,\n",
    "    con=engine,\n",
    "    schema=TARGET_SCHEMA,\n",
    "    if_exists=\"append\",\n",
    "    index=False,\n",
    "    chunksize=5000,\n",
    "    method=\"multi\"\n",
    ")\n",
    "\n",
    "print(f\"Silver carregada: {len(df_load):,} registros\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
